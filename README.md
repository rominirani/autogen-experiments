Experiments demonstrating [Autogen](https://github.com/microsoft/autogen) framework. 

> AutoGen is an open-source programming framework for building AI agents and facilitating cooperation among multiple agents to solve tasks. AutoGen aims to provide an easy-to-use and flexible framework for accelerating development and research on agentic AI, like PyTorch for Deep Learning.
> It offers features such as agents that can converse with other agents, LLM and tool use support, autonomous and human-in-the-loop workflows, and multi-agent conversation patterns.

![Autogen Framework](https://microsoft.github.io/autogen/0.2/assets/images/autogen_agentchat-250ca64b77b87e70d34766a080bf6ba8.png)

| Folder Name    | Application  | Blog Post  |
| -------------- | ------------ | ---------- |
| [`app1`](app1) | Multi-turn conversation between 2 agents, CFP Writer and CFP Reviewer that converse with each other to improve a CFP. Their conversation lasts the number of `max_turns` mentioned while setting up i.e. initiating the chat.| [Multi-Agent Tutorial Series - Part 1](https://medium.com/google-cloud/multi-agent-interactions-using-autogen-with-gemini-a416008e5df6) |
| [`app2`](app2) | Multi-turn conversation between 2 agents with an explicit termination done by the framework if the CFP Reviewer mentions "looks good". It does not depend on the `max_turns` parameter while initiating the chat. | [Multi-Agent Tutorial Series - Part 2](https://medium.com/google-cloud/multi-agent-interactions-with-autogen-and-gemini-part-2-terminating-conversations-883788137162) |
| [`app3`](app3) | Conversation between a Human Agent and an Autonomous Agent. The Human asks the Autonomous Agent to do a task and then reviews it. The Human can then either terminate the conversation or ask the Autonomous Agent to do the task again.| [Multi-Agent Tutorial Series - Part 3](https://medium.com/google-cloud/tutorial-multi-agent-interactions-with-autogen-and-gemini-part-3-introducing-manual-human-8674fe02b7d9) |
| [`app4`](app4) | This is the same example as `app3` , except that instead of invoking the Gemini models online, we use Ollama locally with the Google Gemma model as the LLM.| [Multi-Agent Tutorial Series - Part 4](https://medium.com/google-cloud/tutorial-multi-agent-interactions-with-autogen-and-gemini-part-4-using-local-llms-c6b2faa6a435) |
| [`app5`](app5) | This application shows integration of [AgentOps.ai](https://www.agentops.ai/), that provides observability (monitoring, metrics, session replays, more) about your agents.| [Multi-Agent Tutorial Series - Part 5](https://medium.com/google-cloud/tutorial-multi-agent-interactions-with-autogen-and-gemini-part-5-agentops-a70912486c13) |
| [`app6`](app6) | This application shows additional features of the framework, especially how to tap into conversation history, summarize conversations and get costs for a conversation between agents.| [Multi-Agent Tutorial Series - Part 6](https://medium.com/google-cloud/tutorial-multi-agent-interactions-with-autogen-and-gemini-part-6-history-summarization-and-3212431ff13d) |
| [`app7`](app7) | This application shows one of the conversation design patterns i.e. Sequential Chat, a sequence of chats between two agents, chained together by a carryover mechanism, which brings the summary of the previous chat to the context of the next chat.| [Multi-Agent Tutorial Series - Part 7](https://medium.com/google-cloud/tutorial-multi-agent-interactions-with-autogen-and-gemini-part-7-sequential-chat-885fe1cc55d0) |
| [`app8`](app8) | This application the Group Chat pattern, where we configure a bunch of agents, blog writer, hashtag generator and then allow a UserProxy Agent to co-ordinate the tasks by picking the right agent for it. | [Multi-Agent Tutorial Series - Part 8](https://medium.com/google-cloud/tutorial-multi-agent-interactions-with-autogen-and-gemini-part-8-group-chat-511440860129) |
